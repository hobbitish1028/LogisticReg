---
title: "Intro_to_LogReg"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Intro_to_LogReg}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r,echo = FALSE,include=FALSE}
library("Rcpp")
library(glmnet)
library(dplyr)
library(ggplot2)
Rcpp::sourceCpp('~/Desktop/Courses/625Bigdata/Logistic_package/src/LogRegCpp.cpp')

Logreg<-function(X,y,maxit = 5000){
  n<-dim(X)[1]
  X<-cbind(rep(0,n),X)
  p<-dim(X)[2]
  ### Use rcpp
  result <- LogRegcpp(X,rep(0,p),y,maxit = maxit)
  result$loss <- result$loss[result$loss !=0 ]
  result$prediction <- result$P > 0.5
  result$accuracy <- mean(result$prediction == y)
  
  return(result)
}

My_predict<-function(fit,newx){
  n<-dim(newx)[1]
  X<-cbind(rep(0,n),newx)
  p<-dim(X)[2]
  result <- X%*%fit$x
  return( as.numeric(result>0))
}

```


## Generating binomial data
The model is Gaussian mixture model:

There are two groups, for sample j with label i (i can be 0 or 1), the distribution is 
$$X_j^i \sim N(\mu_i,\sigma^2)$$ 
The following is an toy example with 20000 samples and 100 features (we use it as training model). Among them, 10000 samples are labeled with 0 and the rest are labeled as 1. And the testing model follows the same design as training model.


```{r}

sigma<-4
set.seed(123)
n<-1e4
p<-1e2
mu1<-rnorm(p)
mu2<-rnorm(p)
X1<-matrix(mu1+rnorm(n*p,0,sigma),n,p,byrow = TRUE)
X2<-matrix(mu2+rnorm(n*p,0,sigma),n,p,byrow = TRUE)
### Train data
X<-rbind(X1,X2)
y<-rep(c(1,0),each=n)
### Test data
test_x<-rbind( matrix(mu1+rnorm(n*p,0,sigma),n,p,byrow = TRUE), 
               matrix(mu2+rnorm(n*p,0,sigma),n,p,byrow = TRUE)  )
test_y<-rep(c(1,0),each=n)

```


## How to use LogReg Function

```{r}
t1<-proc.time()
fit<-Logreg(X,y)
proc.time()-t1

plot(fit$loss,main = "Convergence of the result",xlab = "iteration",ylab = "-loglikelihood")

plot(fit$P[c(1:100,1e4+(1:100))],main="Probability Distribution (Prediction)",xlab = "sample number",ylab = "probability of group 1")
```



##Accuracy of the training data and testing data
```{r}
my_prediction<-My_predict(fit,newx = test_x)
```

### Accuracy of the training data 
```{r}
fit$accuracy
```

### Accuracy of the testing data
```{r}
mean(my_prediction == test_y)
```


## GLMNET Package
```{r}
t1<-proc.time()
fit0<-glmnet(X,y,family = "binomial")
result2<- predict(fit0, newx = X,  type = "class")
proc.time()-t1
```

### Accuracy of the training data (glmnet)
```{r}
mean(result2==y)
```

### Accuracy of the testing data (glmnet)
```{r}
result2<- predict(fit0, newx = test_x,  type = "class")
mean(result2==test_y)
```

```{r}
t1<-proc.time()
fit0<-cv.glmnet(X,y,family = "binomial")
result3<- predict(fit0, newx = X,  type = "class")
proc.time()-t1
```

### Accuracy of the training data (cv.glmnet, with cross validation and lasso penalty)
```{r}
mean(result2==y)
```

### Accuracy of the testing data (cv.glmnet, with cross validation and lasso penalty)
```{r}
result2<- predict(fit0, newx = test_x,  type = "class")
mean(result2==test_y)
```


```{r,echo=FALSE}

class <- rep(c("train","test"),3)
accuracy<-c(0.95585,0.9564,0.9208,0.92072,0.9207,0.95575)
method<- rep(c("My_LogReg","glmnet","cv.glmnet"),each=2)
dat<-data.frame(class,accuracy,method)

ggplot(
  dat %>%
    filter(
      class %in% c("train","test")
    ) %>% group_by(method,class) %>% summarize(
      acc = accuracy
    )
)+ aes(
  x=method,
  y=acc)+
  labs(
    x="Method",
    y="Accuracy"
  )+ geom_col(
    aes(fill=factor(class)),
    position='dodge'
  )+coord_cartesian( ylim = c(0.90, 0.97))+ggtitle("Comparison between three models") +
  theme(plot.title = element_text(hjust = 0.5))
```